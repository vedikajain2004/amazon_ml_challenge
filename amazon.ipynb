{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "QPxst0fv-xT-",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:25.288812Z",
     "start_time": "2025-10-13T18:11:20.040531Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import easyocr\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:25.302911Z",
     "start_time": "2025-10-13T18:11:25.298024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(\"C:/Users/jain2/Downloads/68e8d1d70b66d_student_resource/student_resource/dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"C:/Users/jain2/Downloads/68e8d1d70b66d_student_resource/student_resource/dataset/test.csv\")"
   ],
   "metadata": {
    "id": "5Sg8sf79UUae",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:26.707745Z",
     "start_time": "2025-10-13T18:11:25.307050Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:28.379598Z",
     "start_time": "2025-10-13T18:11:26.820271Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Q4RGxCmYLNc",
    "outputId": "e4bfd3f1-8cc5-4177-c72c-6a07623d0d1a",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:30.227128Z",
     "start_time": "2025-10-13T18:11:28.396371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "def extract_text_from_image(url):\n",
    "    try:\n",
    "        results = reader.readtext(url, detail=0)\n",
    "        return \" \".join(results)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def process_batch_train(df, batch_id, save_dir=\"ocr_cache\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    out_path = os.path.join(save_dir, f\"train_batch_{batch_id}.csv\")\n",
    "    if os.path.exists(out_path):  # skip if already done\n",
    "        print(f\"Skipping batch {batch_id}, already processed.\")\n",
    "        return\n",
    "\n",
    "    with Pool(processes=min(4, cpu_count() // 2)) as pool:  # safe for laptops\n",
    "        texts = list(tqdm(pool.imap(extract_text_from_image, df[\"image_link\"]), total=len(df)))\n",
    "    df[\"ocr_text\"] = texts\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved {out_path}\")\n",
    "\n",
    "def process_batch_test(df, batch_id, save_dir=\"ocr_cache\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    out_path = os.path.join(save_dir, f\"test_batch_{batch_id}.csv\")\n",
    "    if os.path.exists(out_path):  # skip if already done\n",
    "        print(f\"Skipping batch {batch_id}, already processed.\")\n",
    "        return\n",
    "\n",
    "    with Pool(processes=min(4, cpu_count() // 2)) as pool:  # safe for laptops\n",
    "        texts = list(tqdm(pool.imap(extract_text_from_image, df[\"image_link\"]), total=len(df)))\n",
    "    df[\"ocr_text\"] = texts\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved {out_path}\")\n",
    "\n",
    "\n",
    "# run in chunks to avoid memory overload\n",
    "batch_size = 2000\n",
    "for i in range(0, 75000, batch_size):\n",
    "    batch_id = i // batch_size\n",
    "    batch_df_train = train_df.iloc[i:i + batch_size].copy()\n",
    "    process_batch_train(batch_df_train, batch_id)\n",
    "for i in range(0, 75000, batch_size):\n",
    "    batch_id = i // batch_size\n",
    "    batch_df_test = test_df.iloc[i:i + batch_size].copy()\n",
    "    process_batch_test(batch_df_test, batch_id)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping batch 0, already processed.\n",
      "Skipping batch 1, already processed.\n",
      "Skipping batch 2, already processed.\n",
      "Skipping batch 3, already processed.\n",
      "Skipping batch 4, already processed.\n",
      "Skipping batch 5, already processed.\n",
      "Skipping batch 6, already processed.\n",
      "Skipping batch 7, already processed.\n",
      "Skipping batch 8, already processed.\n",
      "Skipping batch 9, already processed.\n",
      "Skipping batch 10, already processed.\n",
      "Skipping batch 11, already processed.\n",
      "Skipping batch 12, already processed.\n",
      "Skipping batch 13, already processed.\n",
      "Skipping batch 14, already processed.\n",
      "Skipping batch 15, already processed.\n",
      "Skipping batch 16, already processed.\n",
      "Skipping batch 17, already processed.\n",
      "Skipping batch 18, already processed.\n",
      "Skipping batch 19, already processed.\n",
      "Skipping batch 20, already processed.\n",
      "Skipping batch 21, already processed.\n",
      "Skipping batch 22, already processed.\n",
      "Skipping batch 23, already processed.\n",
      "Skipping batch 24, already processed.\n",
      "Skipping batch 25, already processed.\n",
      "Skipping batch 26, already processed.\n",
      "Skipping batch 27, already processed.\n",
      "Skipping batch 28, already processed.\n",
      "Skipping batch 29, already processed.\n",
      "Skipping batch 30, already processed.\n",
      "Skipping batch 31, already processed.\n",
      "Skipping batch 32, already processed.\n",
      "Skipping batch 33, already processed.\n",
      "Skipping batch 34, already processed.\n",
      "Skipping batch 35, already processed.\n",
      "Skipping batch 36, already processed.\n",
      "Skipping batch 37, already processed.\n",
      "Skipping batch 0, already processed.\n",
      "Skipping batch 1, already processed.\n",
      "Skipping batch 2, already processed.\n",
      "Skipping batch 3, already processed.\n",
      "Skipping batch 4, already processed.\n",
      "Skipping batch 5, already processed.\n",
      "Skipping batch 6, already processed.\n",
      "Skipping batch 7, already processed.\n",
      "Skipping batch 8, already processed.\n",
      "Skipping batch 9, already processed.\n",
      "Skipping batch 10, already processed.\n",
      "Skipping batch 11, already processed.\n",
      "Skipping batch 12, already processed.\n",
      "Skipping batch 13, already processed.\n",
      "Skipping batch 14, already processed.\n",
      "Skipping batch 15, already processed.\n",
      "Skipping batch 16, already processed.\n",
      "Skipping batch 17, already processed.\n",
      "Skipping batch 18, already processed.\n",
      "Skipping batch 19, already processed.\n",
      "Skipping batch 20, already processed.\n",
      "Skipping batch 21, already processed.\n",
      "Skipping batch 22, already processed.\n",
      "Skipping batch 23, already processed.\n",
      "Skipping batch 24, already processed.\n",
      "Skipping batch 25, already processed.\n",
      "Skipping batch 26, already processed.\n",
      "Skipping batch 27, already processed.\n",
      "Skipping batch 28, already processed.\n",
      "Skipping batch 29, already processed.\n",
      "Skipping batch 30, already processed.\n",
      "Skipping batch 31, already processed.\n",
      "Skipping batch 32, already processed.\n",
      "Skipping batch 33, already processed.\n",
      "Skipping batch 34, already processed.\n",
      "Skipping batch 35, already processed.\n",
      "Skipping batch 36, already processed.\n",
      "Skipping batch 37, already processed.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "import glob\n",
    "train_parts = [pd.read_csv(f) for f in sorted(glob.glob(\"ocr_cache/train_batch_*.csv\"))]\n",
    "train_df = pd.concat(train_parts, ignore_index=True)\n",
    "test_parts = [pd.read_csv(f) for f in sorted(glob.glob(\"ocr_cache/test_batch_*.csv\"))]\n",
    "test_df = pd.concat(test_parts, ignore_index=True)"
   ],
   "metadata": {
    "id": "6SKK1KV8YRpv",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:31.799574Z",
     "start_time": "2025-10-13T18:11:30.242319Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "train_df[\"combined_text\"] = train_df[\"catalog_content\"].astype(str) + \" \" + train_df[\"ocr_text\"].astype(str)\n",
    "test_df[\"combined_text\"] = test_df[\"catalog_content\"].astype(str) + \" \" + test_df[\"ocr_text\"].astype(str)"
   ],
   "metadata": {
    "id": "5ygkxBCWbRTp",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:32.058952Z",
     "start_time": "2025-10-13T18:11:31.815097Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "class PricingDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, is_train=True):\n",
    "        self.texts = df[\"combined_text\"].tolist()\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.labels = df[\"price\"].values.astype(float)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        if self.is_train:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item"
   ],
   "metadata": {
    "id": "oaXubsjcjC9A",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:32.079068Z",
     "start_time": "2025-10-13T18:11:32.076100Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=1  # regression\n",
    ")"
   ],
   "metadata": {
    "id": "IB6QCC4YjFE7",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:35.609827Z",
     "start_time": "2025-10-13T18:11:32.097689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = PricingDataset(train_data, tokenizer)\n",
    "val_dataset = PricingDataset(val_data, tokenizer)\n",
    "test_dataset = PricingDataset(test_df, tokenizer, is_train=False)"
   ],
   "metadata": {
    "id": "TCwrUCpDjJGK",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:35.649199Z",
     "start_time": "2025-10-13T18:11:35.634696Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def smape(preds, labels):\n",
    "    return np.mean(100 * np.abs(preds - labels) / ((np.abs(labels) + np.abs(preds)) / 2))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = preds.flatten()\n",
    "    return {\"smape\": smape(preds, labels)}"
   ],
   "metadata": {
    "id": "96_32qa8jOoJ",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:35.757434Z",
     "start_time": "2025-10-13T18:11:35.678228Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "id": "bYXYODqKjLQF",
    "ExecuteTime": {
     "end_time": "2025-10-13T18:11:35.835073Z",
     "start_time": "2025-10-13T18:11:35.778825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"smape\",\n",
    "    greater_is_better=False,\n",
    "    seed=42,\n",
    "    data_seed=42\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "id": "TRzGPpczjQv2",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-13T18:11:35.859772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jain2\\AppData\\Local\\Temp\\ipykernel_13744\\1406855020.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='177' max='84380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  177/84380 00:06 < 49:59, 28.08 it/s, Epoch 0.02/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "preds = trainer.predict(test_dataset).predictions.flatten()\n",
    "preds = np.maximum(preds, 0)  # enforce positive prices"
   ],
   "metadata": {
    "id": "s18YB5BUjTMo",
    "ExecuteTime": {
     "end_time": "2025-10-13T17:28:06.211346Z",
     "start_time": "2025-10-13T17:27:58.798824Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m preds = \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m)\u001B[49m.predictions.flatten()\n\u001B[32m      2\u001B[39m preds = np.maximum(preds, \u001B[32m0\u001B[39m)  \u001B[38;5;66;03m# enforce positive prices\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4567\u001B[39m, in \u001B[36mTrainer.predict\u001B[39m\u001B[34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4564\u001B[39m start_time = time.time()\n\u001B[32m   4566\u001B[39m eval_loop = \u001B[38;5;28mself\u001B[39m.prediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.use_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.evaluation_loop\n\u001B[32m-> \u001B[39m\u001B[32m4567\u001B[39m output = \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4568\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mPrediction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\n\u001B[32m   4569\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4570\u001B[39m total_batch_size = \u001B[38;5;28mself\u001B[39m.args.eval_batch_size * \u001B[38;5;28mself\u001B[39m.args.world_size\n\u001B[32m   4571\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_jit_compilation_time\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output.metrics:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4675\u001B[39m, in \u001B[36mTrainer.evaluation_loop\u001B[39m\u001B[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4672\u001B[39m observed_num_examples = \u001B[32m0\u001B[39m\n\u001B[32m   4674\u001B[39m \u001B[38;5;66;03m# Main evaluation loop\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4675\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   4676\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Update the observed num examples\u001B[39;49;00m\n\u001B[32m   4677\u001B[39m \u001B[43m    \u001B[49m\u001B[43mobserved_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfind_batch_size\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4678\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobserved_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\accelerate\\data_loader.py:579\u001B[39m, in \u001B[36mDataLoaderShard.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    577\u001B[39m     current_batch = send_to_device(current_batch, \u001B[38;5;28mself\u001B[39m.device, non_blocking=\u001B[38;5;28mself\u001B[39m._non_blocking)\n\u001B[32m    578\u001B[39m \u001B[38;5;28mself\u001B[39m._update_state_dict()\n\u001B[32m--> \u001B[39m\u001B[32m579\u001B[39m next_batch = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    580\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batch_index >= \u001B[38;5;28mself\u001B[39m.skip_batches:\n\u001B[32m    581\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m current_batch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    731\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    732\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m733\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    734\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    735\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    736\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    739\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    788\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m789\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    791\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mPricingDataset.__getitem__\u001B[39m\u001B[34m(self, idx)\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     inputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_length\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m256\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m     19\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m     item = {k: v.squeeze(\u001B[32m0\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs.items()}\n\u001B[32m     21\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_train:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2938\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.__call__\u001B[39m\u001B[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[39m\n\u001B[32m   2936\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._in_target_context_manager:\n\u001B[32m   2937\u001B[39m         \u001B[38;5;28mself\u001B[39m._switch_to_input_mode()\n\u001B[32m-> \u001B[39m\u001B[32m2938\u001B[39m     encodings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mall_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2939\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2940\u001B[39m     \u001B[38;5;28mself\u001B[39m._switch_to_target_mode()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3048\u001B[39m, in \u001B[36mPreTrainedTokenizerBase._call_one\u001B[39m\u001B[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[39m\n\u001B[32m   3026\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.batch_encode_plus(\n\u001B[32m   3027\u001B[39m         batch_text_or_text_pairs=batch_text_or_text_pairs,\n\u001B[32m   3028\u001B[39m         add_special_tokens=add_special_tokens,\n\u001B[32m   (...)\u001B[39m\u001B[32m   3045\u001B[39m         **kwargs,\n\u001B[32m   3046\u001B[39m     )\n\u001B[32m   3047\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3048\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3049\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3050\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3051\u001B[39m \u001B[43m        \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3052\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3053\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3054\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3055\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3056\u001B[39m \u001B[43m        \u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3057\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3058\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding_side\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3059\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3060\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3061\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3062\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3063\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3064\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3065\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3066\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3067\u001B[39m \u001B[43m        \u001B[49m\u001B[43msplit_special_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43msplit_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3068\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3069\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3123\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.encode_plus\u001B[39m\u001B[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[39m\n\u001B[32m   3094\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   3095\u001B[39m \u001B[33;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001B[39;00m\n\u001B[32m   3096\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   3111\u001B[39m \u001B[33;03m        method).\u001B[39;00m\n\u001B[32m   3112\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   3114\u001B[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001B[38;5;28mself\u001B[39m._get_padding_truncation_strategies(\n\u001B[32m   3115\u001B[39m     padding=padding,\n\u001B[32m   3116\u001B[39m     truncation=truncation,\n\u001B[32m   (...)\u001B[39m\u001B[32m   3120\u001B[39m     **kwargs,\n\u001B[32m   3121\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m3123\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3125\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3126\u001B[39m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3127\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpadding_strategy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3128\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtruncation_strategy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtruncation_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3129\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3130\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3131\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3132\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3133\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpadding_side\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3134\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3135\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3136\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3137\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3138\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3139\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3141\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3142\u001B[39m \u001B[43m    \u001B[49m\u001B[43msplit_special_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msplit_special_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msplit_special_tokens\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3143\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3144\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:627\u001B[39m, in \u001B[36mPreTrainedTokenizerFast._encode_plus\u001B[39m\u001B[34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[39m\n\u001B[32m    603\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_encode_plus\u001B[39m(\n\u001B[32m    604\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    605\u001B[39m     text: Union[TextInput, PreTokenizedInput],\n\u001B[32m   (...)\u001B[39m\u001B[32m    624\u001B[39m     **kwargs,\n\u001B[32m    625\u001B[39m ) -> BatchEncoding:\n\u001B[32m    626\u001B[39m     batched_input = [(text, text_pair)] \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;28;01melse\u001B[39;00m [text]\n\u001B[32m--> \u001B[39m\u001B[32m627\u001B[39m     batched_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_batch_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    628\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbatched_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    629\u001B[39m \u001B[43m        \u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    630\u001B[39m \u001B[43m        \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    631\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding_strategy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    632\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtruncation_strategy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtruncation_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    633\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    634\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    635\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    636\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding_side\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    637\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    638\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    639\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    640\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    641\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    642\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    643\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    644\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    645\u001B[39m \u001B[43m        \u001B[49m\u001B[43msplit_special_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43msplit_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    646\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    647\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    649\u001B[39m     \u001B[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001B[39;00m\n\u001B[32m    650\u001B[39m     \u001B[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001B[39;00m\n\u001B[32m    651\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m return_tensors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_overflowing_tokens:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:553\u001B[39m, in \u001B[36mPreTrainedTokenizerFast._batch_encode_plus\u001B[39m\u001B[34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001B[39m\n\u001B[32m    550\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._tokenizer.encode_special_tokens != split_special_tokens:\n\u001B[32m    551\u001B[39m     \u001B[38;5;28mself\u001B[39m._tokenizer.encode_special_tokens = split_special_tokens\n\u001B[32m--> \u001B[39m\u001B[32m553\u001B[39m encodings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_tokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencode_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    554\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    555\u001B[39m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    556\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_pretokenized\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    557\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    559\u001B[39m \u001B[38;5;66;03m# Convert encoding to dict\u001B[39;00m\n\u001B[32m    560\u001B[39m \u001B[38;5;66;03m# `Tokens` has type: tuple[\u001B[39;00m\n\u001B[32m    561\u001B[39m \u001B[38;5;66;03m#                       list[dict[str, list[list[int]]]] or list[dict[str, 2D-Tensor]],\u001B[39;00m\n\u001B[32m    562\u001B[39m \u001B[38;5;66;03m#                       list[EncodingFast]\u001B[39;00m\n\u001B[32m    563\u001B[39m \u001B[38;5;66;03m#                    ]\u001B[39;00m\n\u001B[32m    564\u001B[39m \u001B[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001B[39;00m\n\u001B[32m    565\u001B[39m tokens_and_encodings = [\n\u001B[32m    566\u001B[39m     \u001B[38;5;28mself\u001B[39m._convert_encoding(\n\u001B[32m    567\u001B[39m         encoding=encoding,\n\u001B[32m   (...)\u001B[39m\u001B[32m    576\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m encodings\n\u001B[32m    577\u001B[39m ]\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"sample_id\": test_df[\"sample_id\"],\n",
    "    \"price\": preds\n",
    "})\n",
    "submission.to_csv(\"test_out7.csv\", index=False)\n",
    "print(\"Submission saved to test_out7.csv\")"
   ],
   "metadata": {
    "id": "zFhFV26VjVY-",
    "ExecuteTime": {
     "end_time": "2025-10-13T17:28:06.211248900Z",
     "start_time": "2025-10-13T17:23:43.451908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to test_out7.csv\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Pk7Yo5WWjYQn",
    "ExecuteTime": {
     "end_time": "2025-10-13T17:27:31.839364700Z",
     "start_time": "2025-10-13T17:23:43.528963Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:27:31.843375300Z",
     "start_time": "2025-10-13T17:23:43.550956Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
